{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction import text\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text (text) :\n",
    "    words_List = nltk.word_tokenize(text)\n",
    "    final_list = [elto for elto in words_List if elto not in STOP_WORDS]\n",
    "    return \" \".join(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = text.ENGLISH_STOP_WORDS\n",
    "STOP_WORDS = list(STOP) + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read two .csv files and merge them into one dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data\\\\'\n",
    "channel1 = 'iitztimmy'\n",
    "channel2 = 'pgl'\n",
    "\n",
    "channel1_csv = data_folder + channel1 + '.csv'\n",
    "channel2_csv = data_folder + channel2 + '.csv'\n",
    "\n",
    "df1 = pd.read_csv(channel1_csv, index_col=0)\n",
    "df2 = pd.read_csv(channel2_csv, index_col=0)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True) \n",
    "\n",
    "df.replace(to_replace={'channel': {'#iitztimmy':0, '#pgl':1}}, inplace=True)\n",
    "df.drop(columns='datetime', inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cgtiwnl</td>\n",
       "      <td>0</td>\n",
       "      <td>mfker got gang lmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>out_smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>’ d timmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fourthhokage20</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>streamelements</td>\n",
       "      <td>0</td>\n",
       "      <td>new youtub channel arriv iitzaaaa subscrib sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thedarky5</td>\n",
       "      <td>0</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>blessed909</td>\n",
       "      <td>1</td>\n",
       "      <td>gg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>bydrop</td>\n",
       "      <td>1</td>\n",
       "      <td>astrali realis awara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>bloombird</td>\n",
       "      <td>1</td>\n",
       "      <td>lol konfig push middl xd gogogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>emzee17</td>\n",
       "      <td>1</td>\n",
       "      <td>astrali fan 2022 kekw kekw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>thomasdachz</td>\n",
       "      <td>1</td>\n",
       "      <td>kkona murica kkona babi kkona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5886 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  channel  \\\n",
       "0            cgtiwnl        0   \n",
       "1         out_smoked        0   \n",
       "2     fourthhokage20        0   \n",
       "3     streamelements        0   \n",
       "4          thedarky5        0   \n",
       "...              ...      ...   \n",
       "5995      blessed909        1   \n",
       "5996          bydrop        1   \n",
       "5997       bloombird        1   \n",
       "5998         emzee17        1   \n",
       "5999     thomasdachz        1   \n",
       "\n",
       "                                                message  \n",
       "0                                   mfker got gang lmao  \n",
       "1                                             ’ d timmi  \n",
       "2                                                  ouch  \n",
       "3     new youtub channel arriv iitzaaaa subscrib sec...  \n",
       "4                                                   sad  \n",
       "...                                                 ...  \n",
       "5995                                                 gg  \n",
       "5996                               astrali realis awara  \n",
       "5997                    lol konfig push middl xd gogogo  \n",
       "5998                         astrali fan 2022 kekw kekw  \n",
       "5999                      kkona murica kkona babi kkona  \n",
       "\n",
       "[5886 rows x 3 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we want Sleep = SLEEP = SlEEp = sleeP ETC\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].str.lower()\n",
    "\n",
    "# Drop NaN values\n",
    "df.dropna(inplace=True, subset=['channel', 'message'])\n",
    "\n",
    "# Remove words like: can, could, will, been, would...\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(clean_text)\n",
    "\n",
    "# stem separate words\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].astype(str).str.split()\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Remove rows with empty messages\n",
    "df = df[df['message'].astype(bool)]\n",
    "\n",
    "# Rejoin list of messages to single string message separated by <space>\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns to fit PySpark convention (Probably not necessary) and get features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mfker got gang lmao</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>’ d timmi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ouch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new youtub channel arriv iitzaaaa subscrib sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>gg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>astrali realis awara</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>lol konfig push middl xd gogogo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>astrali fan 2022 kekw kekw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>kkona murica kkona babi kkona</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0                                   mfker got gang lmao      0\n",
       "1                                             ’ d timmi      0\n",
       "2                                                  ouch      0\n",
       "3     new youtub channel arriv iitzaaaa subscrib sec...      0\n",
       "4                                                   sad      0\n",
       "...                                                 ...    ...\n",
       "5995                                                 gg      1\n",
       "5996                               astrali realis awara      1\n",
       "5997                    lol konfig push middl xd gogogo      1\n",
       "5998                         astrali fan 2022 kekw kekw      1\n",
       "5999                      kkona murica kkona babi kkona      1\n",
       "\n",
       "[5886 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'channel': 'label'}, inplace=True)\n",
    "\n",
    "final_df = df.loc[:, ['message', 'label']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pandas DataFrame to PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(final_df)\n",
    "\n",
    "# Uncomment if you want to be as excited as I am right now \n",
    "spark_df.printSchema()\n",
    "# spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.head(5)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(20,[3,6,10,11],[...|\n",
      "|    0|(20,[1,10,12],[2....|\n",
      "|    0|(20,[6],[1.930570...|\n",
      "|    0|(20,[2,4,5,7,11,1...|\n",
      "|    0|(20,[18],[2.31060...|\n",
      "|    0|(20,[15],[2.14526...|\n",
      "|    0|(20,[9],[2.492237...|\n",
      "|    0|(20,[4],[4.431827...|\n",
      "|    0|(20,[4,6],[2.2159...|\n",
      "|    0|(20,[17],[2.09157...|\n",
      "|    0|(20,[1,4,12,17],[...|\n",
      "|    0|(20,[6],[1.930570...|\n",
      "|    0|(20,[4],[6.647740...|\n",
      "|    0|(20,[11],[2.30207...|\n",
      "|    0|(20,[2,3,7,12,19]...|\n",
      "|    0|(20,[15],[2.14526...|\n",
      "|    0|(20,[2,3,5,6,7,8,...|\n",
      "|    0|(20,[0],[2.295307...|\n",
      "|    0|(20,[0],[2.295307...|\n",
      "|    0|(20,[4],[2.215913...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# break the sentence into a list of words\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "words_data = tokenizer.transform(spark_df)\n",
    "\n",
    "# TF section\n",
    "hashing_TF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=2000)\n",
    "featurized_data = hashing_TF.transform(words_data)\n",
    "\n",
    "# IDF section\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idf_model = idf.fit(featurized_data)\n",
    "\n",
    "rescaled_data = idf_model.transform(featurized_data)\n",
    "\n",
    "rescaled_data.select('label', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = rescaled_data.randomSplit(weights=[0.8, 0.2], seed=42)\n",
    "\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "nb = NaiveBayes(smoothing=0.1, modelType='multinomial')\n",
    "\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|             message|label|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|'s 10 min 3 day i...|    0|['s, 10, min, 3, ...|(20,[1,6,8,13,19]...|(20,[1,6,8,13,19]...|[-42.292691079385...|[0.99912316806066...|       0.0|\n",
      "|            's oiler|    0|         ['s, oiler]|(20,[1,8],[1.0,1.0])|(20,[1,8],[2.1152...|[-13.857129226593...|[0.59994793880206...|       0.0|\n",
      "|                 0-0|    0|               [0-0]|     (20,[11],[1.0])|(20,[11],[2.30207...|[-8.5005188499021...|[0.32760197849977...|       1.0|\n",
      "|              10 min|    0|           [10, min]|(20,[13,19],[1.0,...|(20,[13,19],[2.08...|[-13.610436642826...|[0.86865954862321...|       0.0|\n",
      "|               10min|    0|             [10min]|     (20,[18],[1.0])|(20,[18],[2.31060...|[-8.4776840546453...|[0.32848226894185...|       1.0|\n",
      "|           1min damn|    0|        [1min, damn]|(20,[3,18],[1.0,1...|(20,[3,18],[1.726...|[-14.395198787850...|[0.04280766577917...|       1.0|\n",
      "|    3aileigh gn bejj|    0|[3aileigh, gn, bejj]|(20,[11,16,19],[1...|(20,[11,16,19],[2...|[-23.912289313004...|[0.27990983711921...|       1.0|\n",
      "|                4444|    0|              [4444]|      (20,[4],[1.0])|(20,[4],[2.215913...|[-7.9031041848073...|[0.35082670037992...|       1.0|\n",
      "|     6 min ohh kappa|    0|[6, min, ohh, kappa]|(20,[6,8,18,19],[...|(20,[6,8,18,19],[...|[-28.903266317091...|[0.40712063242279...|       1.0|\n",
      "|         6 min panic|    0|     [6, min, panic]|(20,[6,19],[2.0,1...|(20,[6,19],[3.861...|[-18.427954223263...|[0.92259061536884...|       0.0|\n",
      "| 6 minut final sleep|    0|[6, minut, final,...|(20,[6,9,10,13],[...|(20,[6,9,10,13],[...|[-25.207982334611...|[0.97574185948761...|       0.0|\n",
      "|  7 min pepemeltdown|    0|[7, min, pepemelt...|(20,[15,18,19],[1...|(20,[15,18,19],[2...|[-23.319034418264...|[0.12116346017400...|       1.0|\n",
      "|         8 min sleep|    0|     [8, min, sleep]|(20,[9,14,19],[1....|(20,[9,14,19],[2....|[-22.872446720005...|[0.51494933927867...|       0.0|\n",
      "|          9 min sadg|    0|      [9, min, sadg]|(20,[1,8,19],[1.0...|(20,[1,8,19],[2.1...|[-21.702418129534...|[0.53701584041586...|       0.0|\n",
      "|                aaaa|    0|              [aaaa]|      (20,[8],[1.0])|(20,[8],[2.234781...|[-8.3387820933418...|[0.31183818098264...|       1.0|\n",
      "|absolut metagam n...|    0|[absolut, metagam...|(20,[0,1,2,3,4,6,...|(20,[0,1,2,3,4,6,...|[-100.07924779964...|[0.75262925123725...|       0.0|\n",
      "|                  ah|    0|                [ah]|     (20,[16],[1.0])|(20,[16],[2.40762...|[-8.2663624894927...|[0.50440817606315...|       0.0|\n",
      "|bbbbbrrrrruuuuuhhhhh|    0|[bbbbbrrrrruuuuuh...|      (20,[5],[1.0])|(20,[5],[2.237961...|[-6.1254119250202...|[0.87188913328688...|       0.0|\n",
      "|      bedg goodnight|    0|   [bedg, goodnight]|     (20,[12],[2.0])|(20,[12],[3.47475...|[-9.6002127385379...|[0.86283655483423...|       0.0|\n",
      "|bet point oiler s...|    0|[bet, point, oile...|(20,[1,12,14,15,1...|(20,[1,12,14,15,1...|[-38.784770330162...|[0.32097614673455...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.575134168157424\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f'Test set accuracy = {str(accuracy)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
