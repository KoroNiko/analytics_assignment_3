{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction import text\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.143:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x205a3f6f9d0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text (text) :\n",
    "    words_List = nltk.word_tokenize(text)\n",
    "    final_list = [elto for elto in words_List if elto not in STOP_WORDS]\n",
    "    return \" \".join(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = text.ENGLISH_STOP_WORDS\n",
    "STOP_WORDS = list(STOP) + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read two .csv files and merge them into one dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10005, 3)\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data\\\\'\n",
    "channel1 = 'loltyler1'\n",
    "channel2 = 'gothamchess'\n",
    "\n",
    "channel1_csv = data_folder + channel1 + '.csv'\n",
    "channel2_csv = data_folder + channel2 + '.csv'\n",
    "\n",
    "df1 = pd.read_csv(channel1_csv, index_col=0)\n",
    "df2 = pd.read_csv(channel2_csv, index_col=0)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True) \n",
    "\n",
    "df.replace(to_replace={'channel': {'#loltyler1':0, '#gothamchess':1}}, inplace=True)\n",
    "df.drop(columns='datetime', inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valakino</td>\n",
       "      <td>0</td>\n",
       "      <td>kekw heal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pidhiii</td>\n",
       "      <td>0</td>\n",
       "      <td>t1 belong d1 t1 belong d1 t1 belong d1 t1 belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w_clooney1</td>\n",
       "      <td>0</td>\n",
       "      <td>bigbroth hahashrugright curselit mingle curselit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>river_shen_main</td>\n",
       "      <td>0</td>\n",
       "      <td>poppi n't win trade 's just bad clueless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mrp_ositive</td>\n",
       "      <td>0</td>\n",
       "      <td>omegalul kr joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>lukagaric03</td>\n",
       "      <td>1</td>\n",
       "      <td>petpet feelsokayman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>clumsyrook</td>\n",
       "      <td>1</td>\n",
       "      <td>meetbal sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>prestigedgamer</td>\n",
       "      <td>1</td>\n",
       "      <td>windmillll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>mastoblood</td>\n",
       "      <td>1</td>\n",
       "      <td>subway overr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>illuminati7777</td>\n",
       "      <td>1</td>\n",
       "      <td>'m hungri eat arbi 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username  channel  \\\n",
       "1             valakino        0   \n",
       "2              pidhiii        0   \n",
       "3           w_clooney1        0   \n",
       "4      river_shen_main        0   \n",
       "5          mrp_ositive        0   \n",
       "...                ...      ...   \n",
       "10000      lukagaric03        1   \n",
       "10001       clumsyrook        1   \n",
       "10002   prestigedgamer        1   \n",
       "10003       mastoblood        1   \n",
       "10004   illuminati7777        1   \n",
       "\n",
       "                                                 message  \n",
       "1                                              kekw heal  \n",
       "2      t1 belong d1 t1 belong d1 t1 belong d1 t1 belo...  \n",
       "3       bigbroth hahashrugright curselit mingle curselit  \n",
       "4               poppi n't win trade 's just bad clueless  \n",
       "5                                       omegalul kr joke  \n",
       "...                                                  ...  \n",
       "10000                                petpet feelsokayman  \n",
       "10001                                        meetbal sub  \n",
       "10002                                         windmillll  \n",
       "10003                                       subway overr  \n",
       "10004                              'm hungri eat arbi 's  \n",
       "\n",
       "[9873 rows x 3 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we want Sleep = SLEEP = SlEEp = sleeP ETC\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].str.lower()\n",
    "\n",
    "# Drop NaN values\n",
    "df.dropna(inplace=True, subset=['channel', 'message'])\n",
    "\n",
    "# Remove words like: can, could, will, been, would...\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(clean_text)\n",
    "\n",
    "# stem separate words\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].astype(str).str.split()\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Remove rows with empty messages\n",
    "df = df[df['message'].astype(bool)]\n",
    "\n",
    "# Rejoin list of messages to single string message separated by <space>\n",
    "df.loc[:, 'message'] = df.loc[:, 'message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add username to message to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'message'] = df['message'] + ' ' + df['username']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns to fit PySpark convention (Probably not necessary) and get features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kekw heal valakino</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1 belong d1 t1 belong d1 t1 belong d1 t1 belo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bigbroth hahashrugright curselit mingle cursel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poppi n't win trade 's just bad clueless river...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>omegalul kr joke mrp_ositive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>petpet feelsokayman lukagaric03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>meetbal sub clumsyrook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>windmillll prestigedgamer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>subway overr mastoblood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>'m hungri eat arbi 's illuminati7777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "1                                     kekw heal valakino      0\n",
       "2      t1 belong d1 t1 belong d1 t1 belong d1 t1 belo...      0\n",
       "3      bigbroth hahashrugright curselit mingle cursel...      0\n",
       "4      poppi n't win trade 's just bad clueless river...      0\n",
       "5                           omegalul kr joke mrp_ositive      0\n",
       "...                                                  ...    ...\n",
       "10000                    petpet feelsokayman lukagaric03      1\n",
       "10001                             meetbal sub clumsyrook      1\n",
       "10002                          windmillll prestigedgamer      1\n",
       "10003                            subway overr mastoblood      1\n",
       "10004               'm hungri eat arbi 's illuminati7777      1\n",
       "\n",
       "[9873 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'channel': 'label'}, inplace=True)\n",
    "\n",
    "final_df = df.loc[:, ['message', 'label']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pandas DataFrame to PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(final_df)\n",
    "\n",
    "# Uncomment if you want to be as excited as I am right now \n",
    "spark_df.printSchema()\n",
    "# spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.head(5)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(3000,[1152,1430,...|\n",
      "|    0|(3000,[432,1628,2...|\n",
      "|    0|(3000,[1188,1576,...|\n",
      "|    0|(3000,[259,307,38...|\n",
      "|    0|(3000,[1352,2303,...|\n",
      "|    0|(3000,[1144,1703,...|\n",
      "|    0|(3000,[468,1152,2...|\n",
      "|    0|(3000,[345,1364],...|\n",
      "|    0|(3000,[2106,2396,...|\n",
      "|    0|(3000,[1152,1263,...|\n",
      "|    0|(3000,[1659,1846,...|\n",
      "|    0|(3000,[850,1152,1...|\n",
      "|    0|(3000,[2489,2814,...|\n",
      "|    0|(3000,[498,795,85...|\n",
      "|    0|(3000,[907,1243,2...|\n",
      "|    0|(3000,[286,362,15...|\n",
      "|    0|(3000,[51,753,153...|\n",
      "|    0|(3000,[1869,2790]...|\n",
      "|    0|(3000,[995,2170,2...|\n",
      "|    0|(3000,[1145,2697]...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# break the sentence into a list of words\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "words_data = tokenizer.transform(spark_df)\n",
    "\n",
    "# TF section\n",
    "hashing_TF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=200000)\n",
    "featurized_data = hashing_TF.transform(words_data)\n",
    "\n",
    "# IDF section\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idf_model = idf.fit(featurized_data)\n",
    "\n",
    "rescaled_data = idf_model.transform(featurized_data)\n",
    "\n",
    "rescaled_data.select('label', 'features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = rescaled_data.randomSplit(weights=[0.8, 0.2], seed=42)\n",
    "\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "nb = NaiveBayes(smoothing=0.1, modelType='multinomial')\n",
    "\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|             message|label|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|'d funni make vid...|    0|['d, funni, make,...|(3000,[0,325,344,...|(3000,[0,325,344,...|[-470.42383114136...|[1.19021324325452...|       1.0|\n",
      "|'s just sad go wa...|    0|['s, just, sad, g...|(3000,[307,325,38...|(3000,[307,325,38...|[-404.38440372185...|[0.99999999992273...|       0.0|\n",
      "|      -1 egusplosion|    0|   [-1, egusplosion]|(3000,[1336,1979]...|(3000,[1336,1979]...|[-99.214472773224...|[0.22471317457444...|       1.0|\n",
      "|-200 bigbroth bop...|    0|[-200, bigbroth, ...|(3000,[560,840,23...|(3000,[560,840,23...|[-160.19413846067...|[1.0,4.0233271014...|       0.0|\n",
      "|1 pepelaugh ðŸ‘‰ ðŸ’Ž...|    0|[1, pepelaugh, ðŸ‘‰...|(3000,[1034,1250,...|(3000,[1034,1250,...|[-612.18874415440...|[1.0,5.5179263625...|       0.0|\n",
      "|10 loss row compl...|    0|[10, loss, row, c...|(3000,[189,329,58...|(3000,[189,329,58...|[-336.06330059781...|[1.0,9.6178409923...|       0.0|\n",
      "|1t pepelaugh ðŸ‘‰ ?...|    0|[1t, pepelaugh, ?...|(3000,[1034,1250,...|(3000,[1034,1250,...|[-689.24513803428...|[1.0,6.4867622747...|       0.0|\n",
      "|3 cs pog thedevou...|    0|[3, cs, pog, thed...|(3000,[343,645,64...|(3000,[343,645,64...|[-196.24978325158...|[7.33551734092483...|       1.0|\n",
      "|`` infest '' kekw...|    0|[``, infest, '', ...|(3000,[987,1152,1...|(3000,[987,1152,1...|[-188.27636939574...|[0.99999693413123...|       0.0|\n",
      "|`` leagu scene ''...|    0|[``, leagu, scene...|(3000,[387,844,11...|(3000,[387,844,11...|[-239.06992535269...|[0.99973501388749...|       0.0|\n",
      "|`` real leagu pla...|    0|[``, real, leagu,...|(3000,[387,1152,1...|(3000,[387,1152,1...|[-239.54620775625...|[1.0,1.9059128894...|       0.0|\n",
      "|`` u n't need man...|    0|[``, u, n't, need...|(3000,[145,750,78...|(3000,[145,750,78...|[-446.22662031700...|[1.0,1.5641058387...|       0.0|\n",
      "|a_cee_te yes actu...|    0|[a_cee_te, yes, a...|(3000,[94,688,862...|(3000,[94,688,862...|[-453.67128834070...|[1.0,9.6082680435...|       0.0|\n",
      "|      abd gwen_ayaya|    0|   [abd, gwen_ayaya]|(3000,[498,1936],...|(3000,[498,1936],...|[-110.32708917529...|[1.0,1.0581282681...|       0.0|\n",
      "|ad gap confirm me...|    0|[ad, gap, confirm...|(3000,[530,558,20...|(3000,[530,558,20...|[-197.43192216994...|[0.99999710404655...|       0.0|\n",
      "|      afk pugmalone1|    0|   [afk, pugmalone1]|(3000,[1145,2270]...|(3000,[1145,2270]...|[-95.195362532619...|[0.99999790688871...|       0.0|\n",
      "|akuretaki peepopo...|    0|[akuretaki, peepo...|(3000,[388,582,17...|(3000,[388,582,17...|[-144.40946183578...|[0.99999999999999...|       0.0|\n",
      "|       ayaya pexelie|    0|    [ayaya, pexelie]|(3000,[132,2970],...|(3000,[132,2970],...|[-80.190244751090...|[1.0,1.5377471010...|       0.0|\n",
      "|babyrag kr babyra...|    0|[babyrag, kr, bab...|(3000,[865,1352,2...|(3000,[865,1352,2...|[-142.62148141503...|[1.0,1.7512413068...|       0.0|\n",
      "|bad omegalul ekko...|    0|[bad, omegalul, e...|(3000,[956,2536,2...|(3000,[956,2536,2...|[-85.008543604683...|[0.41184465033138...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.8549415515409139\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f'Test set accuracy = {str(accuracy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"models/multinomialNB\")\n",
    "model.write().overwrite().save(\"models/multinomialNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaiveBayesModel.load('models\\\\multinomialNB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
