{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom nltk.stem.snowball import SnowballStemmer\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:10.289288Z","iopub.execute_input":"2022-05-15T13:33:10.289564Z","iopub.status.idle":"2022-05-15T13:33:10.29739Z","shell.execute_reply.started":"2022-05-15T13:33:10.289535Z","shell.execute_reply":"2022-05-15T13:33:10.296078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD DATA","metadata":{}},{"cell_type":"code","source":"# Create dataset: join the info from the 2 channels, change the channel names to 0 and 1.\n\ndef create_dataset(dataframe1, dataframe2):\n    # Load both pandas: \n    \n    df1 = pd.read_csv(dataframe1)\n    df2 = pd.read_csv(dataframe2)\n\n    # Join the two pandas\n    final_df = pd.concat([df1, df2], join=\"inner\")\n\n    # Change the channel name to 0 or 1 (binary classifier):\n    final_df[\"channel\"] = np.where(final_df[\"channel\"] == \"#pgl\", 0, 1)\n    \n    # Drop these 2 columns since they don't provice much information for our problem:\n\n    final_df.drop(\"datetime\", axis=1, inplace=True)\n    final_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n    \n    return final_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:10.700005Z","iopub.execute_input":"2022-05-15T13:33:10.700318Z","iopub.status.idle":"2022-05-15T13:33:10.707728Z","shell.execute_reply.started":"2022-05-15T13:33:10.70027Z","shell.execute_reply":"2022-05-15T13:33:10.706482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = create_dataset(r\"/kaggle/input/dataframes/dataset1.csv\", r\"/kaggle/input/dataframes/df1.csv\")\nprint(final_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:10.883871Z","iopub.execute_input":"2022-05-15T13:33:10.884616Z","iopub.status.idle":"2022-05-15T13:33:10.918647Z","shell.execute_reply.started":"2022-05-15T13:33:10.884585Z","shell.execute_reply":"2022-05-15T13:33:10.917578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:10.976706Z","iopub.execute_input":"2022-05-15T13:33:10.977064Z","iopub.status.idle":"2022-05-15T13:33:10.994336Z","shell.execute_reply.started":"2022-05-15T13:33:10.977031Z","shell.execute_reply":"2022-05-15T13:33:10.993232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOWERCASE","metadata":{}},{"cell_type":"code","source":"# Notice that we want Sleep = SLEEP = SlEEp = sleeP ETC\nfinal_df[\"message\"] = final_df[\"message\"].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:11.289323Z","iopub.execute_input":"2022-05-15T13:33:11.289784Z","iopub.status.idle":"2022-05-15T13:33:11.301425Z","shell.execute_reply.started":"2022-05-15T13:33:11.289736Z","shell.execute_reply":"2022-05-15T13:33:11.300307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REMOVE RAW IF ANY NAN IN IT","metadata":{}},{"cell_type":"code","source":"final_df  = final_df.dropna()\nprint(final_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:11.742002Z","iopub.execute_input":"2022-05-15T13:33:11.74299Z","iopub.status.idle":"2022-05-15T13:33:11.754318Z","shell.execute_reply.started":"2022-05-15T13:33:11.742945Z","shell.execute_reply":"2022-05-15T13:33:11.753239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REMOVE STOPWORDS AND PUNCTUATION SYMBOLS","metadata":{}},{"cell_type":"code","source":"# Import stopwords with scikit-learn\n# Remove words like: can, could, will, been, would...\nfrom sklearn.feature_extraction import text\nstop = text.ENGLISH_STOP_WORDS\nstop_words = list(stop) + list(string.punctuation )\n\ndef clean_text ( text ) :\n    words_List = nltk.word_tokenize(text)\n    final_list = [ elto for elto in words_List if elto not in stop_words ]\n    return (\" \". join ( final_list ))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:12.052596Z","iopub.execute_input":"2022-05-15T13:33:12.053106Z","iopub.status.idle":"2022-05-15T13:33:12.061344Z","shell.execute_reply.started":"2022-05-15T13:33:12.053058Z","shell.execute_reply":"2022-05-15T13:33:12.060362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df[\"message\"] = final_df[\"message\"].apply( clean_text )","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:12.375737Z","iopub.execute_input":"2022-05-15T13:33:12.376032Z","iopub.status.idle":"2022-05-15T13:33:13.394571Z","shell.execute_reply.started":"2022-05-15T13:33:12.376004Z","shell.execute_reply":"2022-05-15T13:33:13.393454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:13.878071Z","iopub.execute_input":"2022-05-15T13:33:13.87896Z","iopub.status.idle":"2022-05-15T13:33:13.89605Z","shell.execute_reply.started":"2022-05-15T13:33:13.878886Z","shell.execute_reply":"2022-05-15T13:33:13.894966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEMMING","metadata":{}},{"cell_type":"code","source":"# Stemming is the process of reducing inflection in words (e.g. connection, connects, connected) to their root form (e.g. connect). \n# Use English stemmer.\nstemmer = SnowballStemmer(\"english\")\n\nfinal_df['message'] = final_df['message'].astype(str).str.split()\nfinal_df['message'] = final_df['message'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n\nprint(final_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:14.72902Z","iopub.execute_input":"2022-05-15T13:33:14.73006Z","iopub.status.idle":"2022-05-15T13:33:15.107054Z","shell.execute_reply.started":"2022-05-15T13:33:14.730014Z","shell.execute_reply":"2022-05-15T13:33:15.106099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DROP THE ROWS THAT DON'T HAVE ANY MESSAGE! ","metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:40:22.440756Z","iopub.execute_input":"2022-05-15T11:40:22.441042Z","iopub.status.idle":"2022-05-15T11:40:22.458049Z","shell.execute_reply.started":"2022-05-15T11:40:22.441006Z","shell.execute_reply":"2022-05-15T11:40:22.457415Z"}}},{"cell_type":"code","source":"indexes_to_remove = []\nfor i, element in enumerate(final_df[\"message\"]):\n    if len(element) == 0:\n        indexes_to_remove.append(i)\n        \n# We want to drop the rows that are in this index!  \nprint(indexes_to_remove)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:15.63745Z","iopub.execute_input":"2022-05-15T13:33:15.637725Z","iopub.status.idle":"2022-05-15T13:33:15.646228Z","shell.execute_reply.started":"2022-05-15T13:33:15.637694Z","shell.execute_reply":"2022-05-15T13:33:15.645004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df = final_df.drop(final_df.index[indexes_to_remove])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:16.310156Z","iopub.execute_input":"2022-05-15T13:33:16.310501Z","iopub.status.idle":"2022-05-15T13:33:16.32146Z","shell.execute_reply.started":"2022-05-15T13:33:16.31047Z","shell.execute_reply":"2022-05-15T13:33:16.320349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:17.00838Z","iopub.execute_input":"2022-05-15T13:33:17.008692Z","iopub.status.idle":"2022-05-15T13:33:17.016382Z","shell.execute_reply.started":"2022-05-15T13:33:17.008654Z","shell.execute_reply":"2022-05-15T13:33:17.01511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHOW A WORD CLOUD FOR EACH CHANNEL (MOST COMMON WORDS)","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud \n\n\n# Select the messages for each class\ndf1_clean = final_df[final_df[\"channel\"] == 0]\ndf2_clean = final_df[final_df[\"channel\"] == 1]\n\n# Create string of the messages to insert it into the wordcloud\ndf1_messages_to_string = []\nfor element in df1_clean[\"message\"]:\n    for i in element:\n        df1_messages_to_string.append(i)\n        \ndf2_messages_to_string = []\nfor element in df2_clean[\"message\"]:\n    for i in element:\n        df2_messages_to_string.append(i)\n        \nword_cloud_df1 = WordCloud(collocations = False, background_color = 'white').generate(\" \".join(df1_messages_to_string))\nword_cloud_df2 = WordCloud(collocations = False, background_color = 'white').generate(\" \".join(df2_messages_to_string))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:18.977307Z","iopub.execute_input":"2022-05-15T13:33:18.977593Z","iopub.status.idle":"2022-05-15T13:33:19.527894Z","shell.execute_reply.started":"2022-05-15T13:33:18.977564Z","shell.execute_reply":"2022-05-15T13:33:19.526868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the generated image:\nplt.imshow(word_cloud_df1, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:19.53042Z","iopub.execute_input":"2022-05-15T13:33:19.530726Z","iopub.status.idle":"2022-05-15T13:33:20.060493Z","shell.execute_reply.started":"2022-05-15T13:33:19.530686Z","shell.execute_reply":"2022-05-15T13:33:20.059225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the generated image:\nplt.imshow(word_cloud_df2, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:20.062713Z","iopub.execute_input":"2022-05-15T13:33:20.063095Z","iopub.status.idle":"2022-05-15T13:33:20.318439Z","shell.execute_reply.started":"2022-05-15T13:33:20.063051Z","shell.execute_reply":"2022-05-15T13:33:20.317497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform to string\n\ndef list_to_string(text ) :\n    text = \" \".join(text)\n    return text\n\nfinal_df[\"message\"] = [list_to_string(elto) for elto in final_df[\"message\"]]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:36.494561Z","iopub.execute_input":"2022-05-15T13:33:36.49503Z","iopub.status.idle":"2022-05-15T13:33:36.510767Z","shell.execute_reply.started":"2022-05-15T13:33:36.494987Z","shell.execute_reply":"2022-05-15T13:33:36.509805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:49.377424Z","iopub.execute_input":"2022-05-15T13:33:49.377776Z","iopub.status.idle":"2022-05-15T13:33:49.395985Z","shell.execute_reply.started":"2022-05-15T13:33:49.377743Z","shell.execute_reply":"2022-05-15T13:33:49.394736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DIVIDE DATA: TRAIN & SPLIT","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(final_df[\"message\"], final_df[\"channel\"], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:52.487235Z","iopub.execute_input":"2022-05-15T13:33:52.487927Z","iopub.status.idle":"2022-05-15T13:33:52.496484Z","shell.execute_reply.started":"2022-05-15T13:33:52.487892Z","shell.execute_reply":"2022-05-15T13:33:52.495452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NAIVE BAYES CLASSIFIER","metadata":{}},{"cell_type":"code","source":"# ### SKLEARN MULTINOMIAL NAIVE BAYES\n\nfrom sklearn . naive_bayes import MultinomialNB\nfrom sklearn import metrics\nimport sklearn . feature_extraction . text as txt\nfrom sklearn . pipeline import Pipeline\nfrom sklearn . feature_extraction . text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:33:54.228202Z","iopub.execute_input":"2022-05-15T13:33:54.22902Z","iopub.status.idle":"2022-05-15T13:33:54.235202Z","shell.execute_reply.started":"2022-05-15T13:33:54.228985Z","shell.execute_reply":"2022-05-15T13:33:54.234247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Equivalent to CountVectorizer followed by TfidfTransformer .\ntf = TfidfVectorizer()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:09.485361Z","iopub.execute_input":"2022-05-15T13:34:09.486032Z","iopub.status.idle":"2022-05-15T13:34:09.491693Z","shell.execute_reply.started":"2022-05-15T13:34:09.48599Z","shell.execute_reply":"2022-05-15T13:34:09.490434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:09.703461Z","iopub.execute_input":"2022-05-15T13:34:09.704033Z","iopub.status.idle":"2022-05-15T13:34:09.714721Z","shell.execute_reply.started":"2022-05-15T13:34:09.703997Z","shell.execute_reply":"2022-05-15T13:34:09.713507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Return a document - term matrix\nvectors = tf.fit_transform(X_train)\nvectors_test = tf.transform(X_test)\nprint (vectors.shape , vectors_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:09.903494Z","iopub.execute_input":"2022-05-15T13:34:09.904066Z","iopub.status.idle":"2022-05-15T13:34:09.973451Z","shell.execute_reply.started":"2022-05-15T13:34:09.904027Z","shell.execute_reply":"2022-05-15T13:34:09.972266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nclfNB = MultinomialNB ( alpha =0.01)\nclfNB.fit(vectors , y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:34:59.125255Z","iopub.execute_input":"2022-05-15T13:34:59.125564Z","iopub.status.idle":"2022-05-15T13:34:59.13851Z","shell.execute_reply.started":"2022-05-15T13:34:59.125535Z","shell.execute_reply":"2022-05-15T13:34:59.136533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test scores\npred = clfNB.predict(vectors_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:35:20.402069Z","iopub.execute_input":"2022-05-15T13:35:20.402416Z","iopub.status.idle":"2022-05-15T13:35:20.409599Z","shell.execute_reply.started":"2022-05-15T13:35:20.402385Z","shell.execute_reply":"2022-05-15T13:35:20.408172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:35:23.946123Z","iopub.execute_input":"2022-05-15T13:35:23.946443Z","iopub.status.idle":"2022-05-15T13:35:23.953366Z","shell.execute_reply.started":"2022-05-15T13:35:23.946412Z","shell.execute_reply":"2022-05-15T13:35:23.952256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clfNB.score(vectors_test , y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:35:41.967643Z","iopub.execute_input":"2022-05-15T13:35:41.967983Z","iopub.status.idle":"2022-05-15T13:35:41.97756Z","shell.execute_reply.started":"2022-05-15T13:35:41.967953Z","shell.execute_reply":"2022-05-15T13:35:41.97614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat = metrics.confusion_matrix (y_test , pred )","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:36:03.074008Z","iopub.execute_input":"2022-05-15T13:36:03.074551Z","iopub.status.idle":"2022-05-15T13:36:03.082372Z","shell.execute_reply.started":"2022-05-15T13:36:03.074517Z","shell.execute_reply":"2022-05-15T13:36:03.08116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:38:27.200058Z","iopub.execute_input":"2022-05-15T13:38:27.200523Z","iopub.status.idle":"2022-05-15T13:38:27.207673Z","shell.execute_reply.started":"2022-05-15T13:38:27.200475Z","shell.execute_reply":"2022-05-15T13:38:27.206488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cm = pd.DataFrame( mat)\nplt.figure(figsize =(10 ,10) )\nsn.heatmap(df_cm, annot = True)\nplt.show ()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:39:12.017571Z","iopub.execute_input":"2022-05-15T13:39:12.017885Z","iopub.status.idle":"2022-05-15T13:39:12.280954Z","shell.execute_reply.started":"2022-05-15T13:39:12.01784Z","shell.execute_reply":"2022-05-15T13:39:12.280047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clfNB.score(vectors, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:41:41.918634Z","iopub.execute_input":"2022-05-15T13:41:41.918938Z","iopub.status.idle":"2022-05-15T13:41:41.929106Z","shell.execute_reply.started":"2022-05-15T13:41:41.918908Z","shell.execute_reply":"2022-05-15T13:41:41.927762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:42:11.535892Z","iopub.execute_input":"2022-05-15T13:42:11.5367Z","iopub.status.idle":"2022-05-15T13:42:11.553889Z","shell.execute_reply.started":"2022-05-15T13:42:11.536665Z","shell.execute_reply":"2022-05-15T13:42:11.552482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}